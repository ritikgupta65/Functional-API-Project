{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\gupta\\anaconda3\\envs\\env3\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\gupta\\anaconda3\\envs\\env3\\lib\\site-packages (from scikit-learn) (1.20.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\gupta\\anaconda3\\envs\\env3\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\gupta\\anaconda3\\envs\\env3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\gupta\\anaconda3\\envs\\env3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chemical_Composition</th>\n",
       "      <th>Casting_Temperature</th>\n",
       "      <th>Cooling_Water_Temperature</th>\n",
       "      <th>Casting_Speed</th>\n",
       "      <th>Entry_Temperature</th>\n",
       "      <th>Emulsion_Temperature</th>\n",
       "      <th>Emulsion_Pressure</th>\n",
       "      <th>Emulsion_Concentration</th>\n",
       "      <th>Quench_Water_Pressure</th>\n",
       "      <th>UTS</th>\n",
       "      <th>Elongation</th>\n",
       "      <th>Conductivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99.478527</td>\n",
       "      <td>711.405603</td>\n",
       "      <td>28.642544</td>\n",
       "      <td>2.096182</td>\n",
       "      <td>466.811166</td>\n",
       "      <td>36.873380</td>\n",
       "      <td>3.021007</td>\n",
       "      <td>4.861370</td>\n",
       "      <td>5.042363</td>\n",
       "      <td>407.769487</td>\n",
       "      <td>303.382990</td>\n",
       "      <td>522.625158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99.501888</td>\n",
       "      <td>690.231352</td>\n",
       "      <td>27.379460</td>\n",
       "      <td>1.992219</td>\n",
       "      <td>454.475459</td>\n",
       "      <td>46.429592</td>\n",
       "      <td>2.870779</td>\n",
       "      <td>4.427672</td>\n",
       "      <td>5.104180</td>\n",
       "      <td>395.484844</td>\n",
       "      <td>297.619190</td>\n",
       "      <td>509.135106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99.495372</td>\n",
       "      <td>686.469337</td>\n",
       "      <td>31.121681</td>\n",
       "      <td>1.777955</td>\n",
       "      <td>444.343311</td>\n",
       "      <td>43.306861</td>\n",
       "      <td>2.990477</td>\n",
       "      <td>5.361889</td>\n",
       "      <td>5.188181</td>\n",
       "      <td>397.321979</td>\n",
       "      <td>291.853759</td>\n",
       "      <td>503.386597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99.504719</td>\n",
       "      <td>703.615670</td>\n",
       "      <td>24.821359</td>\n",
       "      <td>2.005000</td>\n",
       "      <td>438.612619</td>\n",
       "      <td>39.847255</td>\n",
       "      <td>2.928425</td>\n",
       "      <td>5.035677</td>\n",
       "      <td>4.999391</td>\n",
       "      <td>401.416533</td>\n",
       "      <td>291.891292</td>\n",
       "      <td>506.849821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99.562917</td>\n",
       "      <td>707.608637</td>\n",
       "      <td>35.152301</td>\n",
       "      <td>2.095548</td>\n",
       "      <td>445.815306</td>\n",
       "      <td>46.203942</td>\n",
       "      <td>2.911283</td>\n",
       "      <td>4.118233</td>\n",
       "      <td>4.978095</td>\n",
       "      <td>404.676258</td>\n",
       "      <td>298.439388</td>\n",
       "      <td>514.657929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>99.479693</td>\n",
       "      <td>721.511526</td>\n",
       "      <td>28.133627</td>\n",
       "      <td>1.899414</td>\n",
       "      <td>461.356680</td>\n",
       "      <td>37.568044</td>\n",
       "      <td>2.924101</td>\n",
       "      <td>5.288165</td>\n",
       "      <td>4.957817</td>\n",
       "      <td>416.977190</td>\n",
       "      <td>297.636585</td>\n",
       "      <td>521.170179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>99.518512</td>\n",
       "      <td>700.638310</td>\n",
       "      <td>24.144670</td>\n",
       "      <td>1.961693</td>\n",
       "      <td>460.828384</td>\n",
       "      <td>36.020653</td>\n",
       "      <td>3.204339</td>\n",
       "      <td>4.896974</td>\n",
       "      <td>5.048852</td>\n",
       "      <td>407.207113</td>\n",
       "      <td>292.802376</td>\n",
       "      <td>502.218274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>99.504640</td>\n",
       "      <td>692.332029</td>\n",
       "      <td>28.312229</td>\n",
       "      <td>1.993117</td>\n",
       "      <td>439.318008</td>\n",
       "      <td>42.956966</td>\n",
       "      <td>3.050226</td>\n",
       "      <td>4.486198</td>\n",
       "      <td>5.324015</td>\n",
       "      <td>398.679553</td>\n",
       "      <td>291.939350</td>\n",
       "      <td>507.839776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>99.465535</td>\n",
       "      <td>685.871693</td>\n",
       "      <td>34.166579</td>\n",
       "      <td>2.112024</td>\n",
       "      <td>453.226642</td>\n",
       "      <td>33.519708</td>\n",
       "      <td>2.987985</td>\n",
       "      <td>4.149120</td>\n",
       "      <td>5.159304</td>\n",
       "      <td>398.350556</td>\n",
       "      <td>291.586699</td>\n",
       "      <td>506.991789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>99.471818</td>\n",
       "      <td>695.384496</td>\n",
       "      <td>32.341455</td>\n",
       "      <td>1.945380</td>\n",
       "      <td>440.763969</td>\n",
       "      <td>40.332685</td>\n",
       "      <td>3.097852</td>\n",
       "      <td>4.823542</td>\n",
       "      <td>5.360230</td>\n",
       "      <td>406.591543</td>\n",
       "      <td>297.563145</td>\n",
       "      <td>512.066370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Chemical_Composition  Casting_Temperature  Cooling_Water_Temperature  \\\n",
       "0                 99.478527           711.405603                  28.642544   \n",
       "1                 99.501888           690.231352                  27.379460   \n",
       "2                 99.495372           686.469337                  31.121681   \n",
       "3                 99.504719           703.615670                  24.821359   \n",
       "4                 99.562917           707.608637                  35.152301   \n",
       "...                     ...                  ...                        ...   \n",
       "99995             99.479693           721.511526                  28.133627   \n",
       "99996             99.518512           700.638310                  24.144670   \n",
       "99997             99.504640           692.332029                  28.312229   \n",
       "99998             99.465535           685.871693                  34.166579   \n",
       "99999             99.471818           695.384496                  32.341455   \n",
       "\n",
       "       Casting_Speed  Entry_Temperature  Emulsion_Temperature  \\\n",
       "0           2.096182         466.811166             36.873380   \n",
       "1           1.992219         454.475459             46.429592   \n",
       "2           1.777955         444.343311             43.306861   \n",
       "3           2.005000         438.612619             39.847255   \n",
       "4           2.095548         445.815306             46.203942   \n",
       "...              ...                ...                   ...   \n",
       "99995       1.899414         461.356680             37.568044   \n",
       "99996       1.961693         460.828384             36.020653   \n",
       "99997       1.993117         439.318008             42.956966   \n",
       "99998       2.112024         453.226642             33.519708   \n",
       "99999       1.945380         440.763969             40.332685   \n",
       "\n",
       "       Emulsion_Pressure  Emulsion_Concentration  Quench_Water_Pressure  \\\n",
       "0               3.021007                4.861370               5.042363   \n",
       "1               2.870779                4.427672               5.104180   \n",
       "2               2.990477                5.361889               5.188181   \n",
       "3               2.928425                5.035677               4.999391   \n",
       "4               2.911283                4.118233               4.978095   \n",
       "...                  ...                     ...                    ...   \n",
       "99995           2.924101                5.288165               4.957817   \n",
       "99996           3.204339                4.896974               5.048852   \n",
       "99997           3.050226                4.486198               5.324015   \n",
       "99998           2.987985                4.149120               5.159304   \n",
       "99999           3.097852                4.823542               5.360230   \n",
       "\n",
       "              UTS  Elongation  Conductivity  \n",
       "0      407.769487  303.382990    522.625158  \n",
       "1      395.484844  297.619190    509.135106  \n",
       "2      397.321979  291.853759    503.386597  \n",
       "3      401.416533  291.891292    506.849821  \n",
       "4      404.676258  298.439388    514.657929  \n",
       "...           ...         ...           ...  \n",
       "99995  416.977190  297.636585    521.170179  \n",
       "99996  407.207113  292.802376    502.218274  \n",
       "99997  398.679553  291.939350    507.839776  \n",
       "99998  398.350556  291.586699    506.991789  \n",
       "99999  406.591543  297.563145    512.066370  \n",
       "\n",
       "[100000 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\gupta\\Downloads\\aluminium_wire_rod_dataset (1).csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "y = df.iloc[:,9:12]\n",
    "X = df.iloc[:, 0:9]\n",
    "X= pd.DataFrame(X)\n",
    "y= pd.DataFrame(y)\n",
    "print(type(X))\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# x_train , x_test , y_train, y_test = train_test_split(x , y , test_size= 0.2 , random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train.shape , x_test.shape , y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X= scaler.fit_transform(X)\n",
    "y = scaler.fit_transform(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Input(shape = (X.shape[1],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h1 =  Dense(512 , activation = 'relu')(x)\n",
    "# h2=  Dense(256 , activation = 'relu')(h1)\n",
    "# h3=  Dense(128 , activation = 'relu')(h2)\n",
    "# h4=  Dense(64 , activation = 'relu')(h3)\n",
    "# h5=  Dense(32 , activation = 'relu')(h4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = Dense(512, activation='relu')(x)\n",
    "h1 = BatchNormalization()(h1)\n",
    "h1 = Dropout(0.3)(h1)\n",
    "\n",
    "h2 = Dense(256, activation='relu')(h1)\n",
    "h2 = BatchNormalization()(h2)\n",
    "h2 = Dropout(0.3)(h2)\n",
    "\n",
    "h3 = Dense(128, activation='relu')(h2)\n",
    "h3 = BatchNormalization()(h3)\n",
    "h3 = Dropout(0.3)(h3)\n",
    "\n",
    "h4 = Dense(64, activation='relu')(h3)\n",
    "h4 = BatchNormalization()(h4)\n",
    "h4 = Dropout(0.3)(h4)\n",
    "\n",
    "h5 = Dense(32, activation='relu')(h4)\n",
    "h5 = BatchNormalization()(h5)\n",
    "h5 = Dropout(0.3)(h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output1  = Dense(1 , activation=  'linear' , name = 'UTS_output')(h5)\n",
    "output2  = Dense(1 , activation=  'linear' , name = 'Elongation_output')(h5)\n",
    "output3  = Dense(1 , activation=  'linear' , name = 'Conductivity_output' )(h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs = x , outputs= [output1 , output2 , output3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 9)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          5120        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 512)          2048        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 512)          0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          131328      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256)          1024        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          32896       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128)          512         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128)          0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           8256        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 64)           256         dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 64)           0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 32)           2080        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32)           128         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32)           0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "UTS_output (Dense)              (None, 1)            33          dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Elongation_output (Dense)       (None, 1)            33          dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Conductivity_output (Dense)     (None, 1)            33          dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 183,747\n",
      "Trainable params: 181,763\n",
      "Non-trainable params: 1,984\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "optimizer = Adam(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=   Adam(learning_rate=0.0001)\n",
    "model.compile(loss = {'UTS_output':'mae' , 'Elongation_output':'mae' ,'Conductivity_output':'mae'} , optimizer = optimizer,\n",
    "              metrics={'UTS_output': 'mae', 'Elongation_output': 'mae', 'Conductivity_output': 'mae'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  metrics = {'UTS_output':'accuracy' , 'Elongation_output':'accuracy' ,'Conductivity_output':'accuracy'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 1.7509 - UTS_output_loss: 0.6449 - Elongation_output_loss: 0.5845 - Conductivity_output_loss: 0.5215 - UTS_output_mae: 0.6449 - Elongation_output_mae: 0.5845 - Conductivity_output_mae: 0.5215 - val_loss: 1.6805 - val_UTS_output_loss: 0.6274 - val_Elongation_output_loss: 0.5643 - val_Conductivity_output_loss: 0.4888 - val_UTS_output_mae: 0.6274 - val_Elongation_output_mae: 0.5643 - val_Conductivity_output_mae: 0.4888\n",
      "Epoch 2/25\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 1.7494 - UTS_output_loss: 0.6440 - Elongation_output_loss: 0.5855 - Conductivity_output_loss: 0.5199 - UTS_output_mae: 0.6440 - Elongation_output_mae: 0.5855 - Conductivity_output_mae: 0.5199 - val_loss: 1.6836 - val_UTS_output_loss: 0.6278 - val_Elongation_output_loss: 0.5651 - val_Conductivity_output_loss: 0.4907 - val_UTS_output_mae: 0.6278 - val_Elongation_output_mae: 0.5651 - val_Conductivity_output_mae: 0.4907\n",
      "Epoch 3/25\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 1.7503 - UTS_output_loss: 0.6453 - Elongation_output_loss: 0.5847 - Conductivity_output_loss: 0.5203 - UTS_output_mae: 0.6453 - Elongation_output_mae: 0.5847 - Conductivity_output_mae: 0.5203 - val_loss: 1.6824 - val_UTS_output_loss: 0.6278 - val_Elongation_output_loss: 0.5643 - val_Conductivity_output_loss: 0.4903 - val_UTS_output_mae: 0.6278 - val_Elongation_output_mae: 0.5643 - val_Conductivity_output_mae: 0.4903\n",
      "Epoch 4/25\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 1.7480 - UTS_output_loss: 0.6434 - Elongation_output_loss: 0.5853 - Conductivity_output_loss: 0.5194 - UTS_output_mae: 0.6434 - Elongation_output_mae: 0.5853 - Conductivity_output_mae: 0.5194 - val_loss: 1.6824 - val_UTS_output_loss: 0.6276 - val_Elongation_output_loss: 0.5649 - val_Conductivity_output_loss: 0.4900 - val_UTS_output_mae: 0.6276 - val_Elongation_output_mae: 0.5649 - val_Conductivity_output_mae: 0.4900\n",
      "Epoch 5/25\n",
      "2500/2500 [==============================] - 46s 19ms/step - loss: 1.7464 - UTS_output_loss: 0.6438 - Elongation_output_loss: 0.5835 - Conductivity_output_loss: 0.5191 - UTS_output_mae: 0.6438 - Elongation_output_mae: 0.5835 - Conductivity_output_mae: 0.5191 - val_loss: 1.6826 - val_UTS_output_loss: 0.6279 - val_Elongation_output_loss: 0.5639 - val_Conductivity_output_loss: 0.4909 - val_UTS_output_mae: 0.6279 - val_Elongation_output_mae: 0.5639 - val_Conductivity_output_mae: 0.4909\n",
      "Epoch 6/25\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 1.7486 - UTS_output_loss: 0.6441 - Elongation_output_loss: 0.5845 - Conductivity_output_loss: 0.5200 - UTS_output_mae: 0.6441 - Elongation_output_mae: 0.5845 - Conductivity_output_mae: 0.5200 - val_loss: 1.6833 - val_UTS_output_loss: 0.6279 - val_Elongation_output_loss: 0.5642 - val_Conductivity_output_loss: 0.4912 - val_UTS_output_mae: 0.6279 - val_Elongation_output_mae: 0.5642 - val_Conductivity_output_mae: 0.4912\n",
      "Epoch 7/25\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 1.7480 - UTS_output_loss: 0.6446 - Elongation_output_loss: 0.5834 - Conductivity_output_loss: 0.5201 - UTS_output_mae: 0.6446 - Elongation_output_mae: 0.5834 - Conductivity_output_mae: 0.5201 - val_loss: 1.6834 - val_UTS_output_loss: 0.6275 - val_Elongation_output_loss: 0.5644 - val_Conductivity_output_loss: 0.4915 - val_UTS_output_mae: 0.6275 - val_Elongation_output_mae: 0.5644 - val_Conductivity_output_mae: 0.4915\n",
      "Epoch 8/25\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 1.7480 - UTS_output_loss: 0.6438 - Elongation_output_loss: 0.5839 - Conductivity_output_loss: 0.5203 - UTS_output_mae: 0.6438 - Elongation_output_mae: 0.5839 - Conductivity_output_mae: 0.5203 - val_loss: 1.6819 - val_UTS_output_loss: 0.6277 - val_Elongation_output_loss: 0.5642 - val_Conductivity_output_loss: 0.4900 - val_UTS_output_mae: 0.6277 - val_Elongation_output_mae: 0.5642 - val_Conductivity_output_mae: 0.4900\n",
      "Epoch 9/25\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 1.7469 - UTS_output_loss: 0.6442 - Elongation_output_loss: 0.5843 - Conductivity_output_loss: 0.5183 - UTS_output_mae: 0.6442 - Elongation_output_mae: 0.5843 - Conductivity_output_mae: 0.5183 - val_loss: 1.6824 - val_UTS_output_loss: 0.6278 - val_Elongation_output_loss: 0.5645 - val_Conductivity_output_loss: 0.4902 - val_UTS_output_mae: 0.6278 - val_Elongation_output_mae: 0.5645 - val_Conductivity_output_mae: 0.4902\n",
      "Epoch 10/25\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 1.7472 - UTS_output_loss: 0.6445 - Elongation_output_loss: 0.5842 - Conductivity_output_loss: 0.5185 - UTS_output_mae: 0.6445 - Elongation_output_mae: 0.5842 - Conductivity_output_mae: 0.5185 - val_loss: 1.6835 - val_UTS_output_loss: 0.6274 - val_Elongation_output_loss: 0.5641 - val_Conductivity_output_loss: 0.4920 - val_UTS_output_mae: 0.6274 - val_Elongation_output_mae: 0.5641 - val_Conductivity_output_mae: 0.4920\n",
      "Epoch 11/25\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 1.7458 - UTS_output_loss: 0.6436 - Elongation_output_loss: 0.5832 - Conductivity_output_loss: 0.5190 - UTS_output_mae: 0.6436 - Elongation_output_mae: 0.5832 - Conductivity_output_mae: 0.5190 - val_loss: 1.6822 - val_UTS_output_loss: 0.6277 - val_Elongation_output_loss: 0.5639 - val_Conductivity_output_loss: 0.4906 - val_UTS_output_mae: 0.6277 - val_Elongation_output_mae: 0.5639 - val_Conductivity_output_mae: 0.4906\n",
      "Epoch 12/25\n",
      "2500/2500 [==============================] - 47s 19ms/step - loss: 1.7460 - UTS_output_loss: 0.6434 - Elongation_output_loss: 0.5826 - Conductivity_output_loss: 0.5200 - UTS_output_mae: 0.6434 - Elongation_output_mae: 0.5826 - Conductivity_output_mae: 0.5200 - val_loss: 1.6835 - val_UTS_output_loss: 0.6276 - val_Elongation_output_loss: 0.5643 - val_Conductivity_output_loss: 0.4916 - val_UTS_output_mae: 0.6276 - val_Elongation_output_mae: 0.5643 - val_Conductivity_output_mae: 0.4916\n",
      "Epoch 13/25\n",
      "2500/2500 [==============================] - 52s 21ms/step - loss: 1.7455 - UTS_output_loss: 0.6426 - Elongation_output_loss: 0.5839 - Conductivity_output_loss: 0.5190 - UTS_output_mae: 0.6426 - Elongation_output_mae: 0.5839 - Conductivity_output_mae: 0.5190 - val_loss: 1.6826 - val_UTS_output_loss: 0.6282 - val_Elongation_output_loss: 0.5640 - val_Conductivity_output_loss: 0.4904 - val_UTS_output_mae: 0.6282 - val_Elongation_output_mae: 0.5640 - val_Conductivity_output_mae: 0.4904\n",
      "Epoch 14/25\n",
      "2500/2500 [==============================] - 51s 20ms/step - loss: 1.7469 - UTS_output_loss: 0.6426 - Elongation_output_loss: 0.5833 - Conductivity_output_loss: 0.5211 - UTS_output_mae: 0.6426 - Elongation_output_mae: 0.5833 - Conductivity_output_mae: 0.5211 - val_loss: 1.6822 - val_UTS_output_loss: 0.6279 - val_Elongation_output_loss: 0.5642 - val_Conductivity_output_loss: 0.4901 - val_UTS_output_mae: 0.6279 - val_Elongation_output_mae: 0.5642 - val_Conductivity_output_mae: 0.4901\n",
      "Epoch 15/25\n",
      "2500/2500 [==============================] - 48s 19ms/step - loss: 1.7441 - UTS_output_loss: 0.6434 - Elongation_output_loss: 0.5832 - Conductivity_output_loss: 0.5175 - UTS_output_mae: 0.6434 - Elongation_output_mae: 0.5832 - Conductivity_output_mae: 0.5175 - val_loss: 1.6809 - val_UTS_output_loss: 0.6275 - val_Elongation_output_loss: 0.5640 - val_Conductivity_output_loss: 0.4895 - val_UTS_output_mae: 0.6275 - val_Elongation_output_mae: 0.5640 - val_Conductivity_output_mae: 0.4895\n",
      "Epoch 16/25\n",
      "2500/2500 [==============================] - 61s 25ms/step - loss: 1.7467 - UTS_output_loss: 0.6439 - Elongation_output_loss: 0.5838 - Conductivity_output_loss: 0.5191 - UTS_output_mae: 0.6439 - Elongation_output_mae: 0.5838 - Conductivity_output_mae: 0.5191 - val_loss: 1.6820 - val_UTS_output_loss: 0.6279 - val_Elongation_output_loss: 0.5634 - val_Conductivity_output_loss: 0.4907 - val_UTS_output_mae: 0.6279 - val_Elongation_output_mae: 0.5634 - val_Conductivity_output_mae: 0.4907\n",
      "Epoch 17/25\n",
      "2500/2500 [==============================] - 89s 36ms/step - loss: 1.7432 - UTS_output_loss: 0.6430 - Elongation_output_loss: 0.5826 - Conductivity_output_loss: 0.5176 - UTS_output_mae: 0.6430 - Elongation_output_mae: 0.5826 - Conductivity_output_mae: 0.5176 - val_loss: 1.6807 - val_UTS_output_loss: 0.6279 - val_Elongation_output_loss: 0.5638 - val_Conductivity_output_loss: 0.4889 - val_UTS_output_mae: 0.6279 - val_Elongation_output_mae: 0.5638 - val_Conductivity_output_mae: 0.4889ss: 0.5828 - Conductivity_output_loss: 0.5193 - UTS_output_mae: 0.6421 - Elongation_outp - ETA: 22s - loss: 1.7431 - UTS_output_loss: 0.6418 - Elongation_output_loss: 0.5829 - Conductivity_output_loss: 0.5184 - UTS_output_mae: 0.6418 - Elongation_output_mae: 0.5829 - Conductivit - ETA: 2s - loss: 1.7435 - UTS_output_loss: 0.6429 - Elongation_output_loss: 0.5832 - Conductivity_output_loss: 0.5174 - UTS_output_mae: \n",
      "Epoch 18/25\n",
      "2500/2500 [==============================] - 90s 36ms/step - loss: 1.7445 - UTS_output_loss: 0.6438 - Elongation_output_loss: 0.5826 - Conductivity_output_loss: 0.5181 - UTS_output_mae: 0.6438 - Elongation_output_mae: 0.5826 - Conductivity_output_mae: 0.5181 - val_loss: 1.6822 - val_UTS_output_loss: 0.6281 - val_Elongation_output_loss: 0.5640 - val_Conductivity_output_loss: 0.4901 - val_UTS_output_mae: 0.6281 - val_Elongation_output_mae: 0.5640 - val_Conductivity_output_mae: 0.4901\n",
      "Epoch 19/25\n",
      "2500/2500 [==============================] - 92s 37ms/step - loss: 1.7436 - UTS_output_loss: 0.6435 - Elongation_output_loss: 0.5826 - Conductivity_output_loss: 0.5174 - UTS_output_mae: 0.6435 - Elongation_output_mae: 0.5826 - Conductivity_output_mae: 0.5174 - val_loss: 1.6835 - val_UTS_output_loss: 0.6278 - val_Elongation_output_loss: 0.5651 - val_Conductivity_output_loss: 0.4906 - val_UTS_output_mae: 0.6278 - val_Elongation_output_mae: 0.5651 - val_Conductivity_output_mae: 0.4906\n",
      "Epoch 20/25\n",
      "2500/2500 [==============================] - 94s 38ms/step - loss: 1.7475 - UTS_output_loss: 0.6439 - Elongation_output_loss: 0.5830 - Conductivity_output_loss: 0.5205 - UTS_output_mae: 0.6439 - Elongation_output_mae: 0.5830 - Conductivity_output_mae: 0.5205 - val_loss: 1.6815 - val_UTS_output_loss: 0.6281 - val_Elongation_output_loss: 0.5640 - val_Conductivity_output_loss: 0.4895 - val_UTS_output_mae: 0.6281 - val_Elongation_output_mae: 0.5640 - val_Conductivity_output_mae: 0.4895\n",
      "Epoch 21/25\n",
      "2500/2500 [==============================] - 93s 37ms/step - loss: 1.7450 - UTS_output_loss: 0.6430 - Elongation_output_loss: 0.5827 - Conductivity_output_loss: 0.5193 - UTS_output_mae: 0.6430 - Elongation_output_mae: 0.5827 - Conductivity_output_mae: 0.5193 - val_loss: 1.6840 - val_UTS_output_loss: 0.6275 - val_Elongation_output_loss: 0.5648 - val_Conductivity_output_loss: 0.4918 - val_UTS_output_mae: 0.6275 - val_Elongation_output_mae: 0.5648 - val_Conductivity_output_mae: 0.4918\n",
      "Epoch 22/25\n",
      "2500/2500 [==============================] - 102s 41ms/step - loss: 1.7439 - UTS_output_loss: 0.6430 - Elongation_output_loss: 0.5829 - Conductivity_output_loss: 0.5179 - UTS_output_mae: 0.6430 - Elongation_output_mae: 0.5829 - Conductivity_output_mae: 0.5179 - val_loss: 1.6818 - val_UTS_output_loss: 0.6275 - val_Elongation_output_loss: 0.5648 - val_Conductivity_output_loss: 0.4896 - val_UTS_output_mae: 0.6275 - val_Elongation_output_mae: 0.5648 - val_Conductivity_output_mae: 0.4896\n",
      "Epoch 23/25\n",
      "2500/2500 [==============================] - 100s 40ms/step - loss: 1.7430 - UTS_output_loss: 0.6427 - Elongation_output_loss: 0.5823 - Conductivity_output_loss: 0.5181 - UTS_output_mae: 0.6427 - Elongation_output_mae: 0.5823 - Conductivity_output_mae: 0.5181 - val_loss: 1.6810 - val_UTS_output_loss: 0.6273 - val_Elongation_output_loss: 0.5640 - val_Conductivity_output_loss: 0.4898 - val_UTS_output_mae: 0.6273 - val_Elongation_output_mae: 0.5640 - val_Conductivity_output_mae: 0.4898\n",
      "Epoch 24/25\n",
      "2500/2500 [==============================] - 95s 38ms/step - loss: 1.7439 - UTS_output_loss: 0.6430 - Elongation_output_loss: 0.5829 - Conductivity_output_loss: 0.5180 - UTS_output_mae: 0.6430 - Elongation_output_mae: 0.5829 - Conductivity_output_mae: 0.5180 - val_loss: 1.6811 - val_UTS_output_loss: 0.6272 - val_Elongation_output_loss: 0.5640 - val_Conductivity_output_loss: 0.4899 - val_UTS_output_mae: 0.6272 - val_Elongation_output_mae: 0.5640 - val_Conductivity_output_mae: 0.4899UTS_output_loss: 0.6450 - Elongation_output_loss: 0.5822 - Conductivity_output_loss: 0.5173 - UTS_output_mae: 0.645 - ETA: 24s - loss: 1.7454 - UTS_output_loss: 0.6447 - - ETA: 5s - loss: 1.7452 - UTS_output_loss: 0.6440 - Elongation_output_loss: 0.5828 - Conductivity_output_loss: 0.5184 - UTS_output_mae: 0.6440 - ETA: 2s - loss: 1.7446 - UTS_output_loss: 0.6435 - Elongation_output_loss: 0.5828 - Conductivity_output_loss: 0.5184 - UTS_output_mae: 0.6435 - ETA: 0s - loss: 1.7441 - UTS_output_loss: 0.6430 - Elongation_output_loss: 0.5830 - Conductivity_output_loss: 0.5180 - UTS_output_mae: 0.6430 - Elongation_output_mae: 0.5830 - Conduct\n",
      "Epoch 25/25\n",
      "2500/2500 [==============================] - 95s 38ms/step - loss: 1.7417 - UTS_output_loss: 0.6417 - Elongation_output_loss: 0.5819 - Conductivity_output_loss: 0.5181 - UTS_output_mae: 0.6417 - Elongation_output_mae: 0.5819 - Conductivity_output_mae: 0.5181 - val_loss: 1.6821 - val_UTS_output_loss: 0.6282 - val_Elongation_output_loss: 0.5639 - val_Conductivity_output_loss: 0.4900 - val_UTS_output_mae: 0.6282 - val_Elongation_output_mae: 0.5639 - val_Conductivity_output_mae: 0.4900\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, \n",
    "                    {'UTS_output': y[:, 0], \n",
    "                     'Elongation_output': y[:, 1], \n",
    "                     'Conductivity_output': y[:, 2]},\n",
    "                    epochs=25, \n",
    "                    verbose=True, \n",
    "                    validation_split=0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted UTS: [389.7989]\n",
      "Predicted Elongation: [463.67606]\n",
      "Predicted Conductivity: [513.4946]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "input_data = [99.478527, 711.405603, 28.642544, 2.096182, 466.811166, 36.873380, 3.021007, 4.861370, 5.042363]\n",
    "input_data_reshaped = np.array(input_data).reshape(1, -1)  # Reshape to (1, number_of_features)\n",
    "\n",
    "predictions = model.predict(input_data_reshaped)\n",
    "\n",
    "print(f\"Predicted UTS: {predictions[0][0]}\")\n",
    "print(f\"Predicted Elongation: {predictions[1][0]}\")\n",
    "print(f\"Predicted Conductivity: {predictions[2][0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('func_API.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\n",
      "Version: 2.3.0\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: c:\\users\\gupta\\anaconda3\\envs\\env2\\lib\\site-packages\n",
      "Requires: absl-py, astunparse, gast, google-pasta, grpcio, h5py, keras-preprocessing, numpy, opt-einsum, protobuf, scipy, six, tensorboard, tensorflow-estimator, termcolor, wheel, wrapt\n",
      "Required-by: \n",
      "---\n",
      "Name: numpy\n",
      "Version: 1.23.5\n",
      "Summary: NumPy is the fundamental package for array computing with Python.\n",
      "Home-page: https://www.numpy.org\n",
      "Author: Travis E. Oliphant et al.\n",
      "Author-email: \n",
      "License: BSD\n",
      "Location: c:\\users\\gupta\\anaconda3\\envs\\env2\\lib\\site-packages\n",
      "Requires: \n",
      "Required-by: Bottleneck, contourpy, gensim, h5py, Keras-Applications, Keras-Preprocessing, matplotlib, mkl-fft, mkl-random, numexpr, opt-einsum, pandas, pytorch-tabnet, scikit-learn, scipy, seaborn, tensorboard, tensorflow, transformers, xgboost\n",
      "---\n",
      "Name: pandas\n",
      "Version: 2.0.3\n",
      "Summary: Powerful data structures for data analysis, time series, and statistics\n",
      "Home-page: https://pandas.pydata.org\n",
      "Author: \n",
      "Author-email: The Pandas Development Team <pandas-dev@python.org>\n",
      "License: BSD 3-Clause License\n",
      "        \n",
      "        Copyright (c) 2008-2011, AQR Capital Management, LLC, Lambda Foundry, Inc. and PyData Development Team\n",
      "        All rights reserved.\n",
      "        \n",
      "        Copyright (c) 2011-2023, Open source contributors.\n",
      "        \n",
      "        Redistribution and use in source and binary forms, with or without\n",
      "        modification, are permitted provided that the following conditions are met:\n",
      "        \n",
      "        * Redistributions of source code must retain the above copyright notice, this\n",
      "          list of conditions and the following disclaimer.\n",
      "        \n",
      "        * Redistributions in binary form must reproduce the above copyright notice,\n",
      "          this list of conditions and the following disclaimer in the documentation\n",
      "          and/or other materials provided with the distribution.\n",
      "        \n",
      "        * Neither the name of the copyright holder nor the names of its\n",
      "          contributors may be used to endorse or promote products derived from\n",
      "          this software without specific prior written permission.\n",
      "        \n",
      "        THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
      "        AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
      "        IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
      "        DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n",
      "        FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n",
      "        DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n",
      "        SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n",
      "        CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n",
      "        OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n",
      "        OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
      "        \n",
      "Location: c:\\users\\gupta\\anaconda3\\envs\\env2\\lib\\site-packages\n",
      "Requires: numpy, python-dateutil, pytz, tzdata\n",
      "Required-by: seaborn\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Package(s) not found: ,, ,\n"
     ]
    }
   ],
   "source": [
    "pip show tensorflow , numpy , pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
